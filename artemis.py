# -*- coding: utf-8 -*-
"""artemis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xahQ5KB6V9Of2DhgYT-qvUIqRZ0xNJEt

# Coordenadas DLC:

## leitura_csv
"""

def processar_arquivo(path):
    """
    Processa um arquivo CSV específico.

    Args:
    - path: Caminho do arquivo CSV a ser processado.

    Returns:
    - DataFrame contendo os dados processados do arquivo.
    """
    import pandas as pd

    # Ler o arquivo CSV
    current_df = pd.read_csv(path, dtype=str)

    # Ajustar as colunas do DataFrame
    current_df.columns = current_df.iloc[0].values
    current_df.drop('bodyparts', axis=1, inplace=True)
    current_df.drop(0, inplace=True)
    current_df.columns = [col_name + '_' + current_df.iloc[0].values[i] for i, col_name in enumerate(current_df.columns)]
    current_df.drop(1, inplace=True)
    current_df.reset_index(inplace=True, drop=True)

    # Converter as colunas para o tipo float
    current_df = current_df.astype('float')

    return current_df

def extrair_informacoes_nome_arquivo(file_name, space):
    """
    Extrai informações relevantes do nome de um arquivo.

    Args:
    - file_name: Nome do arquivo a ser processado.

    Returns:
    - Tupla contendo as informações extraídas do nome do arquivo.
    """
    import re

    try:
        id_part, NN_part = file_name.split('DLC')
        id_parts = id_part.split(space)

        id = id_parts[0]
        session_kind = id_parts[1]
        experimental_context = id_parts[2] if len(id_parts) > 2 and id_parts[2] != "" else None

        experimental_type = NN_part.split("_")[2] if len(id_parts) > 5 else NN_part.split("_")[2]

        sex = id[2] if id.startswith("CC") else None

        if session_kind.lower().startswith("tt"):
            phase = "teste"
        elif session_kind.lower().startswith("tr"):
            phase = "treino"
        elif session_kind.lower().startswith("hab"):
            phase = "habituacao"
        else:
            phase = None

        day = re.search(r'\d+', session_kind).group() if re.search(r'\d+', session_kind) else None

    except ValueError:
        print("Formato inválido do nome do arquivo.")
    except IndexError:
        print("Índice inválido ao acessar partes do nome do arquivo.")
    except Exception as e:
        print("Erro:", e)

    return id, sex, session_kind, experimental_type, experimental_context, day, phase

def processar_diretorio(directory, space = "-"):
    """
    Processa todos os arquivos CSV em um diretório.

    Args:
    - directory: Caminho do diretório contendo os arquivos CSV a serem processados.

    Returns:
    - DataFrame contendo todos os dados processados dos arquivos.
    """
    import os
    import pandas as pd

    file_list = os.listdir(directory)
    csv_list = [file_name for file_name in file_list if file_name.endswith(".csv")]

    all_data = pd.DataFrame()

    for file_name in csv_list:
        path = os.path.join(directory, file_name)
        current_df = processar_arquivo(path)

        id, sex, session_kind, experimental_type, experimental_context, day, phase = extrair_informacoes_nome_arquivo(file_name, space)

        current_df.insert(0, 'phase', phase)
        current_df.insert(0, 'day', day)
        current_df.insert(0, 'experimental_context', experimental_context)
        current_df.insert(0, 'experimental_type', experimental_type)
        current_df.insert(0, 'session_kind', session_kind)
        current_df.insert(0, 'sex', sex)
        current_df.insert(0, 'id', id)

        all_data = pd.concat([all_data, current_df], ignore_index=True)

    all_data.reset_index(drop=True, inplace=True)

    dest_directory = f'{directory}/result'

    if not os.path.exists(dest_directory):
        os.makedirs(dest_directory)

    csv_file_path = f'{dest_directory}/all_data.csv'

    all_data.to_csv(csv_file_path, index=False)

    # Confirmar o salvamento
    print(f'DataFrame mesclado salvo como CSV em {csv_file_path}.')

    return csv_file_path

"""## analise_descritiva_coords"""

def explorar_df(dataframe, colunas_analisadas=None, group_col=None, output_file='descricao_dataset_coord.txt'):
    """
    Explore and analyze the specified columns in a DataFrame, and optionally group data by a specific column.

    Parameters:
    - dataframe (DataFrame): The input DataFrame for exploration.
    - colunas_analisadas (list or None): List of columns to analyze. If None, analyzes all object-type columns.
    - group_col (str or None): Optional column to group data by.
    - output_file (str or None): Optional file path to save the output. If None, prints to console.

    Returns:
    - None: Writes output to specified file or prints to console.
    """
    import pandas as pd
    import matplotlib.pyplot as plt
    from io import StringIO

    output_text = ""  # Inicializar uma string vazia para armazenar a saída

    output_text += f"Resultado da Exploração: Descrição do dataset....\n"
    output_text += "\n"
    output_text += "\n"

    if colunas_analisadas is None:
        colunas_analisadas = dataframe.select_dtypes(include='object').columns

    # Explorar as colunas analisadas
    for coluna in colunas_analisadas:
        valores_unicos = dataframe[coluna].unique()
        output_text += f"Valores únicos na coluna '{coluna}': {valores_unicos}\n"

    if group_col:
        # Agrupar por group_col e imprimir valores únicos de 'id'
        grouped_data = dataframe.groupby(group_col)['id'].unique()
        output_text += f"\nValores únicos de 'id' agrupados por '{group_col}':\n{grouped_data}\n"

    colunas_numericas = dataframe.select_dtypes(include=['float', 'int']).columns
    colunas_likelihood = [col for col in colunas_numericas if col.endswith('likelihood')]

    # Explorar as colunas de likelihood
    for coluna in colunas_likelihood:
        # Calcular as frequências em intervalos de 0.1 e imprimir a tabela de frequências
        intervalos = pd.cut(dataframe[coluna], bins=[0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])
        frequencias = intervalos.value_counts(normalize=True).sort_index()
        tabela_frequencias = pd.DataFrame({'Valores': frequencias.index, 'Frequência': frequencias.values})
        output_text += f"\nTabela de Frequências para a coluna '{coluna}':\n{tabela_frequencias}\n"

    output_text += "\n"

    # Capturar a saída de dataframe.info() usando StringIO
    info_output = StringIO()
    dataframe.info(buf=info_output)
    info_output.seek(0)  # Voltar para o início do buffer
    output_text += info_output.read()  # Adicionar a saída de info_output a output_text

    # Salvar a saída em um arquivo de texto se o caminho do arquivo for fornecido
    if output_file:
        with open(output_file, 'w') as file:
            file.write(output_text)
    else:
        print(output_text)

"""## filtro_features"""

def filter_features(dataframe, id=None, phase=None, day=None, session_kind=None, experimental_context=None, context_type=None, sex=None, bodypart=None, selected_columns=None, output_directory=None):
    """
    Applies filters to a DataFrame based on specified values for the given columns and selects specific columns.

    Parameters:
    - dataframe (pd.DataFrame): The target DataFrame.
    - id (str, list, or None): Value or list of values for the 'id' column.
    - phase (str, list, or None): Value or list of values for the 'phase' column.
    - day (int, list, or None): Value or list of values for the 'day' column.
    - session_kind (str, list, or None): Value or list of values for the 'session_kind' column.
    - experimental_context (str, list, or None): Value or list of values for the 'experimental_context' column.
    - context_type (str, list, or None): Value or list of values for the 'context_type' column.
    - sex (str, list, or None): Value or list of values for the 'sex' column.
    - bodypart (str): The body part for which to select columns.
    - selected_columns (list or None): List of columns to select for the final DataFrame.
    - output_directory (str or None): Output directory for saving the result CSV file.

    Returns:
    - pd.DataFrame: Filtered and selected DataFrame.
    """

    import pandas as pd  # Importing pandas at the start of the function

    filters = {
        'id': id,
        'phase': phase,
        'day': day,
        'session_kind': session_kind,
        'experimental_context': experimental_context,
        'context_type': context_type,
        'sex': sex
    }

    result = dataframe.copy()
    result['frame'] = result.index  # Add 'frame' column with index values

    # Check if filters are provided and filter the DataFrame accordingly
    for column, values in filters.items():
        if values is not None:
            if isinstance(values, list):
                valid_values = [val for val in values if val in dataframe[column].unique()]
                result = result[result[column].isin(valid_values)]
            else:
                if values in dataframe[column].unique():
                    result = result[result[column] == values]

    # Reset 'frame' column to start from zero for each combination of 'id' and 'day'
    result['frame'] = result.groupby(['id', 'day']).cumcount()

    # Reorganize columns to move 'frame' to the first position
    result = result[['frame'] + [col for col in result.columns if col != 'frame']]

    # Check if selected_columns are provided and select only those columns
    if selected_columns:
        valid_columns = [col for col in selected_columns if col in result.columns]
        selected_dataframe = result[valid_columns]
    else:
        selected_dataframe = result

    # Determine the output directory for saving the CSV file
    if output_directory is not None:
        output_file = os.path.dirname(output_directory)
        output_file = os.path.join(output_file, "dataset_select.csv")
        selected_dataframe.to_csv(output_file, index=False)
        print("the file is saved")

    return selected_dataframe

"""## Diferença_Pose_xy"""

def calcular_diferenca(df, bodypart):
    """
    Esta função calcula as colunas de diferença (delta_x e delta_y) entre coordenadas consecutivas de uma parte do corpo.

    Parâmetros:
    - df: DataFrame contendo os dados a serem processados.
    - bodypart: Nome da parte do corpo para a qual as coordenadas estão sendo calculadas.

    Retorna:
    - DataFrame com as colunas de diferença adicionadas.
    """
    import pandas as pd

    df['delta_x'] = df[f'{bodypart}_x'].diff()
    df['delta_y'] = df[f'{bodypart}_y'].diff()

    # Preencher os valores NaN com zeros ou valores iniciais
    df['delta_x'].fillna(0, inplace=True)
    df['delta_y'].fillna(0, inplace=True)

    return df

"""# fps_video"""

def calcular_fps(qtd_frames, qtd_minutos):
    """
    Calcula a taxa de quadros por segundo (FPS) com base na quantidade de quadros e na duração em minutos.

    Parâmetros:
    - qtd_frames (int): Quantidade total de quadros.
    - qtd_minutos (float): Duração do vídeo em minutos.

    Retorna:
    - float: Taxa de quadros por segundo (FPS).
    """
    qtd_segundos = qtd_minutos * 60
    fps = qtd_frames / qtd_segundos
    return fps

def calcular_fps_cada_video(df, min):
    """
    Calcula as estatísticas relacionadas a cada vídeo, incluindo a quantidade de frames e o FPS para cada combinação única de 'id' e 'day' em um DataFrame.

    Parâmetros:
    - df (pd.DataFrame): DataFrame contendo as colunas 'id', 'day' e outras informações de quadros.

    Retorna:
    - dict: Um dicionário contendo os resultados para cada vídeo. Cada entrada do dicionário é uma combinação única de 'id' e 'day' com a quantidade de frames e o FPS calculado.
    """
    import pandas as pd  # Manipulação de dados tabulares (DataFrames)

    # Obter todas as combinações únicas de 'id' e 'day'
    combinacoes_unicas = df[['id', 'day']].drop_duplicates()

    # Inicializar um dicionário para armazenar os resultados
    resultados = []

    # Iterar sobre as combinações únicas
    for _, combinacao in combinacoes_unicas.iterrows():
        id_unico = combinacao['id']
        day_unico = combinacao['day']

        # Filtrar o DataFrame para a combinação específica de 'id' e 'day'
        df_filtrado = df[(df['id'] == id_unico) & (df['day'] == day_unico)]

        # Contar o número de frames para a combinação
        qtd_frames = len(df_filtrado)

        # Calcular FPS usando a função fornecida
        fps = calcular_fps(qtd_frames, qtd_minutos=min)

        # Armazenar os resultados no dicionário
        resultados.append({'id_unico': id_unico, 'day_unico': day_unico, 'qtd_frames': qtd_frames, 'fps': fps})

    df_resultado = pd.DataFrame(resultados)

    return df_resultado

"""# reducao_ruido"""

def Downsampling(dataframe, sampling_rate):
    """
    Sample frames from a DataFrame based on a specified sampling rate for each rat and day.

    Parameters:
    - dataframe (pd.DataFrame): The DataFrame to be sampled.
    - sampling_rate (int): The rate at which frames should be sampled for each rat and day.

    Returns:
    - pd.DataFrame: A new DataFrame containing sampled frames.
    """
    import pandas as pd

    sampled_frames_list = []

    for (id_rat, day), group in dataframe.groupby(['id', 'day']):
        sampled_frames = group.iloc[::sampling_rate].reset_index(drop=True)
        sampled_frames_list.append(sampled_frames)

    sampled_data = pd.concat(sampled_frames_list, ignore_index=True)
    return sampled_data

"""# coluna_tempo"""

def calcular_tempo(df, fps_df, bodypart):
    """
    Esta função calcula as colunas de tempo em segundos e minutos com base nos dados do DataFrame e no DataFrame de fps.

    Parâmetros:
    - df: DataFrame contendo os dados a serem processados.
    - fps_df: DataFrame contendo as informações de fps.
    - bodypart: Nome da parte do corpo para a qual as coordenadas estão sendo calculadas.

    Retorna:
    - DataFrame com as colunas de tempo adicionadas.
    """
    import pandas as pd

    if fps_df is None:
        print("Error: fps_df cannot be None.")
        return df

    df = df.reset_index(drop=True)

    # Fundir o DataFrame principal com o DataFrame de fps usando 'id' e 'day'
    df = pd.merge(df, fps_df, on=['id', 'day'])

    df['tempo_segundos'] = df['frame'] / df['fps']
    df['tempo_minutos'] = df['tempo_segundos'] / 60

    # Remover as colunas 'fps' e 'qtd_frames'
    df = df.drop(['fps', 'qtd_frames'], axis=1)

    return df

"""# coluna_distancia"""

def calcular_distancia(df):
    """
    Esta função calcula a coluna de distância euclidiana entre pontos consecutivos em um DataFrame.

    Parâmetros:
    - df: DataFrame contendo as coordenadas e as colunas de diferença (delta_x e delta_y).

    Retorna:
    - DataFrame com a coluna de distância adicionada.
    """
    import pandas as pd
    import numpy as np

    df['distancia_pixels'] = np.sqrt(df['delta_x']**2 + df['delta_y']**2)
    return df

"""# processamento_geral"""

def processar_coordenadas(df, bodypart, fps_df):
    """
    Esta função processa as coordenadas de uma parte do corpo, calculando tempo, diferença e distância.

    Parâmetros:
    - df: DataFrame contendo os dados a serem processados.
    - bodypart: Nome da parte do corpo para a qual as coordenadas estão sendo calculadas.
    - fps_df: DataFrame contendo as informações de fps.

    Retorna:
    - DataFrame com as colunas de tempo, diferença e distância adicionadas.
    """
    import pandas as pd

    df_tempo = calcular_tempo(df, fps_df, bodypart)
    df_diferenca = calcular_diferenca(df_tempo, bodypart)
    df_final = calcular_distancia(df_diferenca)
    return df_final

"""# pixel_cm"""

def convert_pixels(df, column_name, conversion_rate):
    """
    Converts a column in DataFrame from pixels to centimeters.

    Parameters:
    - df (pd.DataFrame): The DataFrame containing the column to be converted.
    - column_name (str): The name of the column to be converted.
    - conversion_rate (float): The conversion rate from pixels to centimeters.

    Returns:
    - pd.DataFrame: The DataFrame with the new column representing distances in centimeters.
    """
    import pandas as pd
    import numpy as np

    df_copy = df.copy()
    df_copy[f"{column_name}_cm"] = df_copy[column_name] / conversion_rate
    df_copy[f"{column_name}_m"] = df_copy[f"{column_name}_cm"] / 100
    return df_copy

"""# Plots"""

def plot_distance_lines(dataframe):
    """
    Plot line charts for distance values over days for each animal.

    Parameters:
    - dataframe (pd.DataFrame): The DataFrame containing distance values for each animal and day.
    """

    import matplotlib.pyplot as plt
    import seaborn as sns

    # Set the style of seaborn
    sns.set(style="whitegrid")

    # Get unique IDs
    unique_ids = dataframe['id'].unique()

    # Plot individual line charts for each animal
    for id_rat in unique_ids:
        animal_data = dataframe[dataframe['id'] == id_rat]
        context_type = animal_data['context_type'].iloc[0]

        plt.figure(figsize=(10, 6))
        sns.lineplot(data=animal_data, x='day', y='distancia_pixels_m_suavizada', marker='o')
        plt.title(f'Distance Over Days - Animal {id_rat} - {context_type}')
        plt.xlabel('Day')
        plt.ylabel('Distance (metros)')
        plt.show()

def calcular_distancia_media_por_janela(dataset, segundos_experimento, tamanho_janela):

    import pandas as pd

    # Calcula o número de janelas com base no tamanho da janela
    numero_janelas = int(segundos_experimento / tamanho_janela)

    # Cria um DataFrame para armazenar os resultados
    resultado = pd.DataFrame(columns=['id', 'day', 'context_type'] + [f'janela{i+1}' for i in range(numero_janelas)] + ['soma_distancias'])

    # Agrupa os dados pelo 'id' e 'day'
    grupos = dataset.groupby(['id', 'day', 'context_type'])

    # Itera sobre cada grupo
    for (id, day, context_type), grupo in grupos:
        # Calcula a distância média em cada janela
        distancias_por_janela = []
        soma_distancias = 0
        for i in range(numero_janelas):
            janela_inicio = i * tamanho_janela
            janela_fim = (i + 1) * tamanho_janela
            distancias_na_janela = grupo[(grupo['tempo_segundos'] >= janela_inicio) & (grupo['tempo_segundos'] < janela_fim)]['distancia_pixels_m_suavizada'].sum()
            soma_distancias += distancias_na_janela
            distancias_por_janela.append(distancias_na_janela)

        # Adiciona os resultados ao DataFrame resultado
        resultado = pd.concat([resultado, pd.DataFrame([[id, day, context_type] + distancias_por_janela + [soma_distancias]], columns=resultado.columns)], ignore_index=True)

    return resultado